#include "UnityCG.cginc"
#include "../../GlobalDefines.cginc"

int screen_width;
int screen_height;

int AtrousIterations;

struct ColData {
	float3 throughput;
	float3 Direct;
	float3 Indirect;
	uint PrimaryNEERay;
	int IsSpecular;
	float pad;
};
StructuredBuffer<ColData> PerPixelRadiance;

float4x4 viewprojection;
float4x4 prevviewprojection;
float4x4 _CameraToWorld;

Texture2D<float4> ColorDirectIn;
Texture2D<float4> ColorIndirectIn;
RWTexture2D<float4> ColorDirectOut;
RWTexture2D<float4> ColorIndirectOut;
RWTexture2D<float4> Result;

Texture2D<float4> _Albedo;
SamplerState sampler_Albedo;

RWTexture2D<float4> RWScreenPosPrev;
Texture2D<float4> ScreenPosPrev;
Texture2D<float4> PosTex;
RWTexture2D<float4> PrevPosTex;
RWTexture2D<int> HistoryTex;
Texture2D<float4> _CameraNormalDepthTex;
SamplerState sampler_CameraNormalDepthTex;

RWTexture2D<float4> FrameBufferMoment;

RWTexture2D<float4> HistoryDirectTex;
RWTexture2D<float4> HistoryIndirectTex;
RWTexture2D<float4> HistoryMomentTex;

RWTexture2D<float4> RWHistoryNormalAndDepth;
RWTexture2D<float4> RWNormalAndDepth;

Texture2D<float4> HistoryNormalAndDepth;
Texture2D<float4> NormalAndDepth;





inline float2 oct_encode_normal(float3 n) {
	n /= (abs(n.x) + abs(n.y) + abs(n.z));

	if (n.z < 0.0f) {
		// Oct wrap
		n.x = (1.0f - abs(n.y)) * (n.x >= 0.0f ? +1.0f : -1.0f);
		n.y = (1.0f - abs(n.x)) * (n.y >= 0.0f ? +1.0f : -1.0f);
	}

	return float2(0.5f * n.x + 0.5f, 0.5f * n.y + 0.5f);
}


#define THRESHOLD_NORMAL 0.95f;
#define THRESHOLD_DEPTH 1.0f;
#pragma kernel kernel_copy

int TargetWidth;
int TargetHeight;


float FarPlane;
RWTexture2D<float4> PrevDepthTexMain;
#ifdef HDRP
	Texture2DArray<float4> NormalTex;
	Texture2DArray<float4> MotionVectors;
#else
	Texture2D<float4> MotionVectors;
	Texture2D<float4> NormalTex;
#endif
Texture2D<float> PrevDepthTex;
Texture2D<float> DepthTex;
SamplerState sampler_MotionVectors;
SamplerState sampler_DepthTex;
SamplerState sampler_PrevDepthTex;
SamplerState sampler_NormalTex;

uint packUnormArb(const float3 data2) {
	const uint4 bits = uint4(10, 10, 10, 0);
	const float4 data = float4(data2, 0);
	float4 mull = exp2(float4(bits)) - 1.0;

	uint4 shift = uint4(0, bits.x, bits.x + bits.y, bits.x + bits.y + bits.z);
	uint4 shifted = uint4(data * mull + 0.5) << shift;

	return shifted.x | shifted.y | shifted.z | shifted.w;
}

float3 unpackUnormArb(const uint pack) {
	const uint4 bits = uint4(10, 10, 10, 0);
	uint4 maxValue = uint4(exp2(bits) - 1);
	uint4 shift = uint4(0, bits.x, bits.x + bits.y, bits.x + bits.y + bits.z);
	uint4 unshifted = pack >> shift;
	unshifted = unshifted & maxValue;

	return normalize((float4(unshifted).xyz * 1.0 / float4(maxValue).xyz).xyz * 2.0f - 1.0f);
}

float3 unpackRGBE(uint x)
{
	int exponent = int(x >> 27) - 20;
	float scale = pow(2, exponent) / 256.0;

	float3 v;
	v.r = float(x & 0x1ff) * scale;
	v.g = float((x >> 9) & 0x1ff) * scale;
	v.b = float((x >> 18) & 0x1ff) * scale;

	return v;
}

float4x4 _CameraInverseProjection;
float3 Forward;

inline float3 CreateCameraRay(float2 uv) {
	// Invert the perspective projection of the view-space position
	float3 direction = mul(_CameraInverseProjection, float4(uv, 0.0f, 1.0f)).xyz;
	// Transform the direction from camera to world space and normalize
	direction = mul(_CameraToWorld, float4(direction, 0.0f)).xyz;
	direction = normalize(direction);

	return direction;
}

[numthreads(16, 16, 1)]
void kernel_copy(int3 id : SV_DispatchThreadID)
{//Reprojects and moves the color data from the array to textures
	if (id.x >= screen_width || id.y >= screen_height) return;
	int pixel_index = id.y * screen_width + id.x;
	float2 UV = id.xy / float2(screen_width, screen_height);
	uint2 NewSample = floor(UV * float2(TargetWidth, TargetHeight));
	float3 Albedo = _Albedo.SampleLevel(sampler_Albedo, id.xy / float2(screen_width, screen_height), 0).xyz;
	float3 Dir = CreateCameraRay(UV * 2.0f - 1.0f);
	ColorDirectOut[id.xy] = float4(PerPixelRadiance[pixel_index].Direct + ((Albedo == 0) ? 0 : unpackRGBE(PerPixelRadiance[pixel_index].PrimaryNEERay) / Albedo), 1.0f);
	ColorIndirectOut[id.xy] = float4(PerPixelRadiance[pixel_index].Indirect, 1.0f);
	#ifdef HDRP
		RWScreenPosPrev[id.xy] = float4((MotionVectors[int3(NewSample, 0)].xy), 0.0f, 1.0f);
		RWNormalAndDepth[id.xy] = float4(oct_encode_normal(NormalTex[int3(NewSample,0)]), DepthTex[id.xy], PrevDepthTex[id.xy]);
	#else
		RWScreenPosPrev[id.xy] = float4((MotionVectors.SampleLevel(sampler_MotionVectors, UV, 0).xy), 0.0f, 1.0f);
		RWNormalAndDepth[id.xy] = float4(oct_encode_normal(NormalTex[NewSample]), DepthTex[id.xy], PrevDepthTex[id.xy].x);
	#endif
}


inline float luminance(const float r, const float g, const float b) {
	return 0.299f * r + 0.587f * g + 0.114f * b;
}


inline float3 oct_decode_normal(float2 f) {
	f = f * 2.0f - 1.0f;

	float3 n = float3(f.x, f.y, 1.0f - abs(f.x) - abs(f.y));

	float t = saturate(-n.z);
	n.x += n.x >= 0.0 ? -t : t;
	n.y += n.y >= 0.0 ? -t : t;

	return normalize(n);
}

inline bool is_tap_consistent(int x, int y, const float3 normal, float depth) {
	if (y < 0 || y >= screen_height || x < 0 || x >= screen_width)  return false;

	float4 prev_normal_and_depth = HistoryNormalAndDepth[int2(x, y)];
	float3 prev_normal = oct_decode_normal(prev_normal_and_depth.xy);
	float  prev_depth = prev_normal_and_depth.z;

	bool consistent_normal = dot(normal, prev_normal) > THRESHOLD_NORMAL;
	bool consistent_depth = abs(depth - prev_depth) / abs(depth) < THRESHOLD_DEPTH;

	return consistent_normal && consistent_depth;
}



#pragma kernel kernel_reproject
bool UseReSTIRGI;
[numthreads(16, 16, 1)]
void kernel_reproject(int3 id : SV_DispatchThreadID)
{
	if (id.x >= screen_width || id.y >= screen_height) return;


	float4 direct = ColorDirectIn[id.xy];
	float4 indirect = ColorIndirectIn[id.xy];

	float4 moment;
	moment.x = luminance(direct.x, direct.y, direct.z);
	moment.y = luminance(indirect.x, indirect.y, indirect.z);
	moment.z = moment.x * moment.x;
	moment.w = moment.y * moment.y;

	float4 normdepth = NormalAndDepth[id.xy];
	float3 normal = oct_decode_normal(normdepth.xy);
	float depth = normdepth.z;
	// float depth_prev = HistoryNormalAndDepth[id.xy].w;

	float2 screen_position_prev = ((((float2(id.xy)+0.5f) * float2(rcp(screen_width), rcp(screen_height)) - ScreenPosPrev[id.xy].xy) * float2(screen_width, screen_height)));//((ScreenPosPrev[id.xy].xy + 1.0f) * 0.5f) * float2(screen_width, screen_height);

	if (depth == 0.0f) {
		ColorDirectOut[id.xy] = ColorDirectIn[id.xy];
		ColorIndirectOut[id.xy] = ColorIndirectIn[id.xy];
		return;
	};
	float4 prev_direct = float4(0.0f, 0.0f, 0.0f, 0.0f);
	float4 prev_indirect = float4(0.0f, 0.0f, 0.0f, 0.0f);
	float4 prev_moment = float4(0.0f, 0.0f, 0.0f, 0.0f);
		float temporal_sum_w_diff = 0.0;
		float temporal_sum_w_spec = 0.0;

		float2 pos_ld = floor(screen_position_prev - 0.5);
		float2 subpix = frac(screen_position_prev - 0.5 - pos_ld);

		// Bilinear/bilateral filter
		static const int2 off[4] = { { 0, 0 }, { 1, 0 }, { 0, 1 }, { 1, 1 } };
		float w[4] = {
			(1.0 - subpix.x) * (1.0 - subpix.y),
			(subpix.x) * (1.0 - subpix.y),
			(1.0 - subpix.x) * (subpix.y),
			(subpix.x) * (subpix.y)
		};
		for (int i = 0; i < 4; i++) {
			int2 p = int2(pos_ld)+off[i];

			if (p.x < 0 || p.x >= screen_width || p.y >= screen_height)
				continue;

			float depth_prev = HistoryNormalAndDepth[p].z;
			float3  normal_prev = oct_decode_normal(HistoryNormalAndDepth[p].xy);
			float3  geo_normal_prev = oct_decode_normal(HistoryNormalAndDepth[p].xy);//needs to be TEX_PT_GEO_NORMAL_B, but since for now I am not worrying about normal maps yet, it can use the same texture

			float dist_depth = (abs(depth - depth_prev)) / abs(depth);
			float dot_normals = dot(normal, normal_prev);
			float dot_geo_normals = dot(normal, geo_normal_prev);

			if (dist_depth < 0.1 && dot_geo_normals > 0.95)
			{

				float w_diff = w[i] * max(dot_normals, 0);

					float4 tap_direct = HistoryDirectTex[p];
					float4 tap_indirect = HistoryIndirectTex[p];
					float4 tap_moment = HistoryMomentTex[p];


				prev_direct += w_diff * tap_direct;
				prev_indirect += w_diff * tap_indirect;
				prev_moment += w_diff * tap_moment;

				temporal_sum_w_diff += w_diff;
			}
		}

		// We found some relevant surfaces - good
		if (temporal_sum_w_diff > 1e-6)
		{
			float inv_w_diff = 1.0 / temporal_sum_w_diff;
			prev_direct *= inv_w_diff;
			prev_indirect *= inv_w_diff;
			prev_moment *= inv_w_diff;
		}


	





	if (temporal_sum_w_diff > 1e-6) {
		// Normalize
		//consistent_weights_sum = max(consistent_weights_sum, 0.1f);
	
		int history = HistoryTex[pos_ld].x + 1; // Increase History Length by 1 step
		// history = min(history,10);
		HistoryTex[id.xy] = history;


		float inv_history = rcp((float)(history));
		float alpha_colour = max(((UseReSTIRGI) ? 0.3f : 0.015), inv_history);
		float alpha_moment = max(((UseReSTIRGI) ? 0.6f : 0.04), inv_history);

		// Integrate using exponential moving average
		direct = lerp(prev_direct, direct, alpha_colour);
		indirect = lerp(prev_indirect, indirect, alpha_colour);
		moment = lerp(prev_moment, moment, alpha_moment);
		if (history >= 4) {
			float variance_direct = max(0.0f, moment.z - moment.x * moment.x);
			float variance_indirect = max(0.0f, moment.w - moment.y * moment.y);

			// Store the Variance in the alpha channels
			direct.w = variance_direct;
			indirect.w = variance_indirect;
		}
	}
	else {
		HistoryTex[id.xy] = 0; // Reset History Length

		direct.w = 1.0f;
		indirect.w = 1.0f;
	}
	ColorDirectOut[id.xy] = direct;
	ColorIndirectOut[id.xy] = indirect;

	FrameBufferMoment[id.xy] = moment;

}


#pragma kernel kernel_variance


#define epsilon 0.000000001f
static float sigma_z = 4.0f;
static float sigma_n = 128.0f;
static float sigma_l = 10.0f;
static float sigma_l_square = 100.0f;
static float luminance_denom = 0.8f;

inline float2 edge_stopping_weights(
	int delta_x,
	int delta_y,
	const float2 center_depth_gradient,
	float center_depth,
	float depth,
	const float3 center_normal,
	const float3 normal,
	float center_luminance_direct,
	float center_luminance_indirect,
	float luminance_direct,
	float luminance_indirect,
	float luminance_denom_direct,
	float luminance_denom_indirect,
	int2 Offset,
	float StepSize
) {
	// ∇z(p)·(p−q) (Actually the negative of this but we take its absolute value)
	float d =
		center_depth_gradient.x * (float)delta_x +
		center_depth_gradient.y * (float)delta_y;

	float ln_w_z = abs(center_depth - depth) / (sigma_z * abs(d) + epsilon);

	float w_n = pow(max(0.0f, dot(center_normal, normal)), sigma_n);

	float w_l_direct = w_n * exp(-abs(center_luminance_direct - luminance_direct) * luminance_denom_direct - ln_w_z);
	float w_l_indirect = w_n * exp(-abs(center_luminance_indirect - luminance_indirect) * luminance_denom_indirect - ln_w_z);

	return float2(w_l_direct, w_l_indirect);
}
int iteration;

[numthreads(16, 16, 1)]
void kernel_variance(int3 id : SV_DispatchThreadID)
{
	if (id.x >= screen_width || id.y >= screen_height) return;
	int history = HistoryTex[id.xy].x;

	if (history >= 4) {
		ColorDirectOut[id.xy] = ColorDirectIn[id.xy];
		ColorIndirectOut[id.xy] = ColorIndirectIn[id.xy];
		return;
	}

	float4 center_color_direct = ColorDirectIn[id.xy];
	float4 center_color_indirect = ColorIndirectIn[id.xy];
	float4 CenterNormalDepth = NormalAndDepth[id.xy];

	float4 center_luminence_direct = luminance(center_color_direct.x, center_color_direct.y, center_color_direct.z);
	float4 center_luminence_indirect = luminance(center_color_indirect.x, center_color_indirect.y, center_color_indirect.z);

	float3 CenterNormal = oct_decode_normal(CenterNormalDepth.xy);
	float CenterDepth = CenterNormalDepth.z;

	float2 center_depth_gradient = float2(
		NormalAndDepth[int2(id.x + 1, id.y)].z - CenterDepth,
		NormalAndDepth[int2(id.x, id.y + 1)].z - CenterDepth);

	if (CenterDepth == 0.0f) {
		ColorDirectOut[id.xy] = ColorDirectIn[id.xy];
		ColorIndirectOut[id.xy] = ColorIndirectIn[id.xy];
		return;
	}


	float sum_weight_direct = 1.0f;
	float sum_weight_indirect = 1.0f;

	float4 sum_colour_direct = center_color_direct;
	float4 sum_colour_indirect = center_color_indirect;

	float4 sum_moment = float4(0.0f, 0.0f, 0.0f, 0.0f);


	int2 tap_index;
	[unroll] for (int j = -3; j <= 3; j++) {
		int tap_y = id.y + j;

		if (tap_y < 0 || tap_y >= screen_height) continue;

		[unroll] for (int i = -3; i <= 3; i++) {
			int tap_x = id.x + i;

			if (tap_x < 0 || tap_x >= screen_width) continue;

			if (i == 0 && j == 0) continue; // Center pixel is treated separately

			tap_index = int2(tap_x, tap_y);

			float4 colour_direct = ColorDirectIn[tap_index];
			float4 colour_indirect = ColorIndirectIn[tap_index];
			float4 moment = FrameBufferMoment[tap_index];
			float4 TappedNormalDepth = NormalAndDepth[tap_index];

			float luminance_direct = luminance(colour_direct.x, colour_direct.y, colour_direct.z);
			float luminance_indirect = luminance(colour_indirect.x, colour_indirect.y, colour_indirect.z);

			float2 w = edge_stopping_weights(
				i, j,
				center_depth_gradient,
				CenterDepth, TappedNormalDepth.z,
				CenterNormal, oct_decode_normal(TappedNormalDepth.xy),
				center_luminence_direct, center_luminence_indirect,
				luminance_direct, luminance_indirect,
				luminance_denom, luminance_denom,
				int2(i, j),
				1
			);

			float w_direct = w.x;
			float w_indirect = w.y;

			sum_weight_direct += w_direct;
			sum_weight_indirect += w_indirect;

			sum_colour_direct += w_direct * colour_direct;
			sum_colour_indirect += w_indirect * colour_indirect;

			sum_moment += moment * float4(w_direct, w_indirect, w_direct, w_indirect);
		}
	}


	sum_weight_direct = max(sum_weight_direct, 0.000001f);
	sum_weight_indirect = max(sum_weight_indirect, 0.000001f);

	sum_colour_direct /= sum_weight_direct;
	sum_colour_indirect /= sum_weight_indirect;

	sum_moment /= float4(sum_weight_direct, sum_weight_indirect, sum_weight_direct, sum_weight_indirect);

	sum_colour_direct.w = max(0.0f, sum_moment.z - sum_moment.x * sum_moment.x);
	sum_colour_indirect.w = max(0.0f, sum_moment.w - sum_moment.y * sum_moment.y);

	// Store the Variance in the alpha channel
	ColorDirectOut[id.xy] = sum_colour_direct;
	ColorIndirectOut[id.xy] = sum_colour_indirect;

}


#pragma kernel kernel_atrous

const static int feedback_iteration = 1;
uniform int step_size;

const static float kernel_gaussian[2][2] = {
	{ 1.0f / 1.0f, 1.0f / 2.0f  },
	{ 1.0f / 2.0f, 1.0f / 4.0f }
};

[numthreads(16, 16, 1)]
void kernel_atrous(int3 id : SV_DispatchThreadID)
{
	if (id.x >= screen_width || id.y >= screen_height) return;

	float variance_blurred_direct = 0.0f;
	float variance_blurred_indirect = 0.0f;
	int i, j, tap_x, tap_y;


	for (j = -1; j <= 1; j++) {
		tap_y = clamp(id.y + j * min(step_size,8), 0, screen_height - 1);
		[unroll]
		for (i = -1; i <= 1; i++) {
			tap_x = clamp(id.x + i * min(step_size,8), 0, screen_width - 1);
			// Read the Variance of Direct/Indirect Illumination
			// The Variance is stored in the alpha channel (w coordinate)
			float variance_direct = ColorDirectIn[int2(tap_x, tap_y)].w;
			float variance_indirect = ColorIndirectIn[int2(tap_x, tap_y)].w;

			float kernel_weight = kernel_gaussian[abs(i)][abs(j)] / min(step_size,8);

			variance_blurred_direct += variance_direct * kernel_weight;
			variance_blurred_indirect += variance_indirect * kernel_weight;
		}
	}

	// Precompute denominators that are loop invariant
	const float luminance_denom_direct = rsqrt(max(0.0f, variance_blurred_direct) + epsilon);
	float luminance_denom_indirect = rsqrt(max(0.0f, variance_blurred_indirect) + epsilon);

	const float4 center_colour_direct = ColorDirectIn[id.xy];
	const float4 center_colour_indirect = ColorIndirectIn[id.xy];

	float center_luminance_direct = luminance(center_colour_direct.x, center_colour_direct.y, center_colour_direct.z);
	float center_luminance_indirect = luminance(center_colour_indirect.x, center_colour_indirect.y, center_colour_indirect.z);

	float4 center_normal_and_depth = NormalAndDepth[id.xy];

	float3 center_normal = oct_decode_normal(center_normal_and_depth.xy);
	float  center_depth = center_normal_and_depth.z;

	// Check if the pixel belongs to the Skybox
	if (center_depth == 0.0f) return;

	float2 center_depth_gradient = float2(
		NormalAndDepth[int2(id.x + 1, id.y)].z - center_depth,
		NormalAndDepth[int2(id.x, id.y + 1)].z - center_depth
		);

	float  sum_weight_direct = 1.0f;
	float  sum_weight_indirect = 1.0f;
	float4 sum_colour_direct = center_colour_direct;
	float4 sum_colour_indirect = center_colour_indirect;

	// Use a 3x3 box filter, as recommended in the A-SVGF paper
	const static int radius = 1;
	float4 color_direct;
	float4 color_indirect;
	float4 normal_and_depth;
	for (j = -radius; j <= radius; j++) {
		tap_y = j * ceil(step_size * abs(1.0f - abs(center_depth_gradient.y))) + id.y;

		if (tap_y < 0 || tap_y >= screen_height) continue;
		[unroll]
		for (i = -radius; i <= radius; i++) {
			tap_x = i * ceil(step_size * abs(1.0f - abs(center_depth_gradient.x))) + id.x;

			if (tap_x < 0 || tap_x >= screen_width || (i == 0 && j == 0)) continue;

			color_direct = ColorDirectIn[int2(tap_x, tap_y)];
			color_indirect = ColorIndirectIn[int2(tap_x, tap_y)];

			float luminance_direct = luminance(color_direct.x, color_direct.y, color_direct.z);
			float luminance_indirect = luminance(color_indirect.x, color_indirect.y, color_indirect.z);

			normal_and_depth = NormalAndDepth[int2(tap_x, tap_y)];

			float3 normal = oct_decode_normal(normal_and_depth.xy);
			float depth = normal_and_depth.z;

			float2 w = edge_stopping_weights(
				i * step_size,
				j * step_size,
				center_depth_gradient,
				center_depth, depth,
				center_normal, normal,
				center_luminance_direct, center_luminance_indirect,
				luminance_direct, luminance_indirect,
				luminance_denom_direct, luminance_denom_indirect,
				int2(i, j),
				step_size
			);

			float weight_direct = w.x;
			float weight_indirect = w.y;

			sum_weight_direct += weight_direct;
			sum_weight_indirect += weight_indirect;

			// Filter Colour using the weights, filter Variance using the square of the weights
			sum_colour_direct += float4(weight_direct, weight_direct, weight_direct, weight_direct * weight_direct) * color_direct;
			sum_colour_indirect += float4(weight_indirect, weight_indirect, weight_indirect, weight_indirect * weight_indirect) * color_indirect;
		}
	}

	float inv_sum_weight_direct = rcp(sum_weight_direct);
	float inv_sum_weight_indirect = rcp(sum_weight_indirect);

	// Normalize
	sum_colour_direct *= inv_sum_weight_direct;
	sum_colour_indirect *= inv_sum_weight_indirect;

	// Alpha channel contains Variance, and needs to be divided by the square of the weights
	sum_colour_direct.w *= inv_sum_weight_direct;
	sum_colour_indirect.w *= inv_sum_weight_indirect;

	ColorDirectOut[id.xy] = sum_colour_direct;
	ColorIndirectOut[id.xy] = sum_colour_indirect;

	if (step_size == 1) {
		HistoryDirectTex[id.xy] = ColorDirectIn[id.xy];
		HistoryIndirectTex[id.xy] = ColorIndirectIn[id.xy];
	}

}



#pragma kernel kernel_finalize

bool DiffRes;

inline float luminance(const float3 a) {
	return dot(float3(0.299f, 0.587f, 0.114f), a);
}
#ifdef HDRP
	Texture2DArray<float4> DiffuseGBuffer;
	Texture2DArray<float4> SpecularGBuffer;
#else
	Texture2D<float4> DiffuseGBuffer;
	Texture2D<float4> SpecularGBuffer;
#endif
SamplerState my_linear_clamp_sampler;
[numthreads(16, 16, 1)]
void kernel_finalize(int3 id : SV_DispatchThreadID)
{
	if (id.x >= screen_width || id.y >= screen_height) return;
	int pixel_index = id.y * screen_width + id.x;
	float3 GBufferCol = 1;
	if(DiffRes) {
	    float2 UV = id.xy / float2(screen_width, screen_height);
	    #ifdef HDRP
	        float3 SpecularAlbedo = 0;//Albedo2[int3(ipos,0)].xyz;
	        GBufferCol = ((DiffuseGBuffer.SampleLevel(my_linear_clamp_sampler, float3(UV, 0), 0).xyz + SpecularAlbedo) == 0) ? 1 : (DiffuseGBuffer.SampleLevel(my_linear_clamp_sampler, float3(UV, 0), 0).xyz + SpecularAlbedo);
	    #else
	        float3 SpecularAlbedo = SpecularGBuffer.SampleLevel(my_linear_clamp_sampler, UV, 0);
	        GBufferCol = ((DiffuseGBuffer.SampleLevel(my_linear_clamp_sampler, UV, 0).xyz + SpecularAlbedo) == 0) ? 1 : ((DiffuseGBuffer.SampleLevel(my_linear_clamp_sampler, UV, 0).xyz + SpecularAlbedo));
	    #endif
	}
	float3 colour = ((ColorDirectIn[id.xy].xyz + ColorIndirectIn[id.xy].xyz) * ( _Albedo.SampleLevel(sampler_Albedo, id.xy / float2(screen_width, screen_height), 0).w == 0 ? 1 : _Albedo.SampleLevel(sampler_Albedo, id.xy / float2(screen_width, screen_height), 0).xyz)) / GBufferCol;
	if (luminance(colour) < 10000) Result[id.xy] = float4(colour, 1);

	HistoryMomentTex[id.xy] = FrameBufferMoment[id.xy];
	RWHistoryNormalAndDepth[id.xy] = NormalAndDepth[id.xy];
}