#pragma kernel kernel_upsample
#include "UnityCG.cginc"

int source_width;
int source_height;

int target_width;
int target_height;

Texture2D<float4> Input;
Texture2D<float4> ThroughputTex;
SamplerState sampler_Input_trilinear_clamp;
RWTexture2D<float4> Output;
RWTexture2D<float4> FinalOutput;
Texture2D<float4> PrevOutput;

float4x4 ViewProjectionMatrix;

Texture2D<float4> NormalTex;
Texture2D<float4> PrevNormalTex;
RWTexture2D<float4> PrevNormalTexWrite;
SamplerState sampler_NormalTex; 
Texture2D<float4> DepthTex;
SamplerState sampler_DepthTex; 
Texture2D<float4> PrevDepthTex;
SamplerState sampler_PrevDepthTex; 
RWTexture2D<float4> PrevDepthTexWrite;
Texture2D<float4> Albedo;
Texture2D<float4> Albedo2;
Texture2D<float4> MotionVectors;
SamplerState sampler_trilinear_clamp;
Texture2D<float4> PrevWorldPos;
RWTexture2D<float4> PrevWorldPosWrite;

float3 CamPos;
float FarPlane;

uint pixel_index;

uint curframe;
uint cursam;


// texture coords for directional sampling
float2 center_pixel;
float2 north_pixel;
float2 south_pixel;
float2 east_pixel;
float2 west_pixel;
float2 north_east_pixel;
float2 north_west_pixel;
float2 south_east_pixel;
float2 south_west_pixel;

// offset coordinates used for super sampling
const float2 offset_uv = float2(0.36, 0.64);

// finds the absolute distance from two floats
float float_diff(float float_a, float float_b) {
    return abs(float_a - float_b);
}

// maximum difference for all 3 color channels
float color_diff(float4 color_a, float4 color_b) {
    float diff_r = float_diff(color_a.r, color_b.r);
    float diff_g = float_diff(color_a.g, color_b.g);
    float diff_b = float_diff(color_a.b, color_b.b);
    return max(diff_r, max(diff_g, diff_b));
}

// simple average of two colors
float4 color_average(float4 color_a, float4 color_b) {
    return lerp(color_a, color_b, 0.5);
}

// take 9 samples and perform a directional average
float4 directional_average() {
    // get the colors of all 9 pixels in the 3x3 grid
    float4 pixel_0 = Input.SampleLevel(sampler_Input_trilinear_clamp, center_pixel, 0.0); // center pixel
    float4 pixel_1 = Input.SampleLevel(sampler_Input_trilinear_clamp, north_pixel, 0.0); // north pixel
    float4 pixel_2 = Input.SampleLevel(sampler_Input_trilinear_clamp, south_pixel, 0.0); // south pixel
    float4 pixel_3 = Input.SampleLevel(sampler_Input_trilinear_clamp, east_pixel, 0.0); // east pixel
    float4 pixel_4 = Input.SampleLevel(sampler_Input_trilinear_clamp, west_pixel, 0.0); // west pixel
    float4 pixel_5 = Input.SampleLevel(sampler_Input_trilinear_clamp, north_east_pixel, 0.0); // north-east pixel
    float4 pixel_6 = Input.SampleLevel(sampler_Input_trilinear_clamp, north_west_pixel, 0.0); // north-west pixel
    float4 pixel_7 = Input.SampleLevel(sampler_Input_trilinear_clamp, south_east_pixel, 0.0); // south-east pixel
    float4 pixel_8 = Input.SampleLevel(sampler_Input_trilinear_clamp, south_west_pixel, 0.0); // south-west pixel
    
    // find the maximum color difference for each of 12 directions
    float dir_1 = color_diff(pixel_0, pixel_1); // center to north
    float dir_2 = color_diff(pixel_0, pixel_2); // center to south
    float dir_3 = color_diff(pixel_0, pixel_3); // center to east
    float dir_4 = color_diff(pixel_0, pixel_4); // center to west
    float dir_5 = color_diff(pixel_0, pixel_5); // center to north-east
    float dir_6 = color_diff(pixel_0, pixel_6); // center to north-west
    float dir_7 = color_diff(pixel_0, pixel_7); // center to south-east
    float dir_8 = color_diff(pixel_0, pixel_8); // center to south-west
    float dir_9 = color_diff(pixel_1, pixel_4); // north to west
    float dir_10 = color_diff(pixel_1, pixel_3); // north to east
    float dir_11 = color_diff(pixel_2, pixel_3); // south to east
    float dir_12 = color_diff(pixel_2, pixel_4); // south to west
    
    // find the minimum distance of each of the 12 directions
    float min_dist = dir_1;
    min_dist = min(min_dist, dir_2);
    min_dist = min(min_dist, dir_3);
    min_dist = min(min_dist, dir_4);
    min_dist = min(min_dist, dir_5);
    min_dist = min(min_dist, dir_6);
    min_dist = min(min_dist, dir_7);
    min_dist = min(min_dist, dir_8);
    min_dist = min(min_dist, dir_9);
    min_dist = min(min_dist, dir_10);
    min_dist = min(min_dist, dir_11);
    min_dist = min(min_dist, dir_12);
    
    // get the average color along the minimum direction
    float4 result = pixel_0;
    if (min_dist == dir_1)
        result = color_average(pixel_0, pixel_1); // center to north
    else if (min_dist == dir_2) 
        result = color_average(pixel_0, pixel_2); // center to south
    else if (min_dist == dir_3) 
        result = color_average(pixel_0, pixel_3); // center to east
    else if (min_dist == dir_4) 
        result = color_average(pixel_0, pixel_4); // center to west
    else if (min_dist == dir_5) 
        result = color_average(pixel_0, pixel_5); // center to north-east
    else if (min_dist == dir_6) 
        result = color_average(pixel_0, pixel_6); // center to north-west
    else if (min_dist == dir_7) 
        result = color_average(pixel_0, pixel_7); // center to south-east
    else if (min_dist == dir_8) 
        result = color_average(pixel_0, pixel_8); // center to south-west
    else if (min_dist == dir_9) 
        result = color_average(pixel_0, color_average(pixel_1, pixel_4)); // north to west
    else if (min_dist == dir_10) 
        result = color_average(pixel_0, color_average(pixel_1, pixel_3)); // north to east
    else if (min_dist == dir_11) 
        result = color_average(pixel_0, color_average(pixel_2, pixel_3)); // south to east
    else if (min_dist == dir_12) 
        result = color_average(pixel_0, color_average(pixel_2, pixel_4)); // south to west
    return result;
}

// partial derivative on x-axis
float2 deriv_x(float2 pos, float4 frag, float2 pixel) {
    float2 offset = float2(pixel.x, 0.0);
    float2 pos_plus = pos + offset;
    float2 pos_minus = pos - offset;
    int coord = int(frag.x) / 2;
    bool even = int(coord * 2) == int(frag.x);
    return even ? (pos_plus - pos) : (pos - pos_minus);
}

// partial derivative on y-axis
float2 deriv_y(float2 pos, float4 frag, float2 pixel) {
    float2 offset = float2(0.0, pixel.y);
    float2 pos_plus = pos + offset;
    float2 pos_minus = pos - offset;
    int coord = int(frag.y) / 2;
    bool even = int(coord * 2) == int(frag.y);
    return even ? (pos_plus - pos) : (pos - pos_minus);
}

// take 4 samples in a rotated grid for super sampling
float4 super_sample(float2 base_uv, float4 frag, float2 pixel) {
    float2 dx = deriv_x(base_uv, frag, pixel);
    float2 dy = deriv_y(base_uv, frag, pixel);
    float2 uv = 0.0;
    float4 color = 0.0;
    uv = base_uv + offset_uv.x * dx + offset_uv.y * dy;
    color += Input.SampleLevel(sampler_Input_trilinear_clamp, uv, 0.0);
    uv = base_uv - offset_uv.x * dx - offset_uv.y * dy;
    color += Input.SampleLevel(sampler_Input_trilinear_clamp, uv, 0.0);
    uv = base_uv + offset_uv.y * dx - offset_uv.x * dy;
    color += Input.SampleLevel(sampler_Input_trilinear_clamp, uv, 0.0);
    uv = base_uv - offset_uv.y * dx + offset_uv.x * dy;
    color += Input.SampleLevel(sampler_Input_trilinear_clamp, uv, 0.0);
    color *= 0.25;
    return color;
}

float4x4 _CameraToWorld;
float4x4 _CameraInverseProjection;
float4x4 _PrevCameraToWorld;
float4x4 _PrevCameraInverseProjection;

float3 Forward;
float3 PrevCamPos;

float3 CreateCameraRayPrev(float2 uv, float depth) {
    float3 origin = mul(_PrevCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;
    // Invert the perspective projection of the view-space position
    float3 direction = mul(_PrevCameraInverseProjection, float4(uv, 0.0f, 1.0f)).xyz;
    // Transform the direction from camera to world space and normalize
    direction = mul(_PrevCameraToWorld, float4(direction, 0.0f)).xyz;
    direction = normalize(direction);
    return origin + direction * depth;
}   

float3 CreateCameraRay(float2 uv, out float depth) {
    float3 origin = mul(unity_CameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;
    // Invert the perspective projection of the view-space position
    float3 direction = mul(_CameraInverseProjection, float4(uv, 0.0f, 1.0f)).xyz;
    // Transform the direction from camera to world space and normalize
    direction = mul(unity_CameraToWorld, float4(direction, 0.0f)).xyz;
    direction = normalize(direction);
    depth = length(direction / dot(direction, Forward) * LinearEyeDepth(DepthTex.SampleLevel(sampler_DepthTex, uv, 0).x));
    return origin + direction * depth;
}   

float2 v_sel(float2 f, float val, float eq, float2 neq)
{
    float2 result;
    result.x = (f.x == val) ? eq : neq.x;
    result.y = (f.y == val) ? eq : neq.y;
    return result;
}
#define M_PI 3.14159

float luminance(float3 c)
{
    return 0.212671 * c.x + 0.715160 * c.y + 0.072169 * c.z;
}



[numthreads(16,16,1)]
void kernel_upsample (int3 id : SV_DispatchThreadID)
{
    if (id.x >= target_width || id.y >= target_height) return;
    
    pixel_index = id.y * target_width + id.x;
    float2 UV2 = float2(id.xy) / float2(target_width, target_height);
    float2 texel = 0.5f / float2(target_width, target_height);
    float2 motion = MotionVectors.SampleLevel(sampler_trilinear_clamp, UV2, 0).xy;
    float2 newUV = int2((UV2 * float2(target_width, target_height) - motion * float2(target_width, target_height) + 0.5f)) / float2(target_width, target_height);//UV - MotionVectors.SampleLevel(sampler_trilinear_clamp, UV, 0).xy + texel;
    

    float2 UV = id.xy / float2(target_width, target_height) * float2(source_width, source_height);
    float2 tc = floor(UV - 0.5) + 0.5;
    float2 f = UV - tc + 2;

    // compute at f, f-1, f-2, f-3, f-4, and f-5 using trig angle addition
    float2 fpi = f * M_PI, fpi3 = f * (M_PI / 3.0);
    float2 sinfpi = sin(fpi), sinfpi3 = sin(fpi3), cosfpi3 = cos(fpi3);
    const float r3 = sqrt(3.0);
    float2 w0 = v_sel(f, 0, M_PI * M_PI * 1.0 / 3.0, (sinfpi *       sinfpi3) / (f       * f));
    float2 w1 = v_sel(f, 1, M_PI * M_PI * 2.0 / 3.0, (-sinfpi * (sinfpi3 - r3 * cosfpi3)) / ((f - 1.0)*(f - 1.0)));
    float2 w2 = v_sel(f, 2, M_PI * M_PI * 2.0 / 3.0, (sinfpi * (-sinfpi3 - r3 * cosfpi3)) / ((f - 2.0)*(f - 2.0)));
    float2 w3 = v_sel(f, 3, M_PI * M_PI * 2.0 / 3.0, (-sinfpi * (-2.0*sinfpi3)) / ((f - 3.0)*(f - 3.0)));
    float2 w4 = v_sel(f, 4, M_PI * M_PI * 2.0 / 3.0, (sinfpi * (-sinfpi3 + r3 * cosfpi3)) / ((f - 4.0)*(f - 4.0)));
    float2 w5 = v_sel(f, 5, M_PI * M_PI * 2.0 / 3.0, (-sinfpi * (sinfpi3 + r3 * cosfpi3)) / ((f - 5.0)*(f - 5.0)));

    // use bilinear texture weights to merge center two samples in each dimension
    float2 Weight[5];
    Weight[0] = w0;
    Weight[1] = w1;
    Weight[2] = w2 + w3;
    Weight[3] = w4;
    Weight[4] = w5;

    float2 invTextureSize = 1.0 / float2(source_width, source_height);

    float2 Sample[5];
    Sample[0] = invTextureSize * (tc - 2);
    Sample[1] = invTextureSize * (tc - 1);
    Sample[2] = invTextureSize * (tc + w3 / Weight[2]);
    Sample[3] = invTextureSize * (tc + 2);
    Sample[4] = invTextureSize * (tc + 3);

    float Depth;
    float3 WorldPos = CreateCameraRay(UV2, Depth);
    float3 PreviousWorldPosition = CreateCameraRayPrev(newUV, PrevDepthTex.SampleLevel(sampler_PrevDepthTex, newUV, 0).x);
    PrevDepthTexWrite[id.xy] = float4(Depth, 0, 0, 1);
    bool Disocluded = length(WorldPos - PrevWorldPos[newUV * float2(target_width, target_height)].xyz) > 0.1 * Depth || dot(PrevNormalTex.SampleLevel(sampler_Input_trilinear_clamp, newUV, 0).xyz * 2.0 - 1.0f, NormalTex[id.xy].xyz * 2.0 - 1.0f) < 0.99f;
        if(any(newUV >= 1) || any(newUV <= 0)) Disocluded = true;


   float4 o_rgba = 0;

    // 5x5 footprint with corners dropped to give 13 texture taps
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[0].x, Sample[2].y), 0).rgb, 1.0) * Weight[0].x * Weight[2].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[1].x, Sample[1].y), 0).rgb, 1.0) * Weight[1].x * Weight[1].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[1].x, Sample[2].y), 0).rgb, 1.0) * Weight[1].x * Weight[2].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[1].x, Sample[3].y), 0).rgb, 1.0) * Weight[1].x * Weight[3].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[2].x, Sample[0].y), 0).rgb, 1.0) * Weight[2].x * Weight[0].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[2].x, Sample[1].y), 0).rgb, 1.0) * Weight[2].x * Weight[1].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[2].x, Sample[2].y), 0).rgb, 1.0) * Weight[2].x * Weight[2].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[2].x, Sample[3].y), 0).rgb, 1.0) * Weight[2].x * Weight[3].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[2].x, Sample[4].y), 0).rgb, 1.0) * Weight[2].x * Weight[4].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[3].x, Sample[1].y), 0).rgb, 1.0) * Weight[3].x * Weight[1].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[3].x, Sample[2].y), 0).rgb, 1.0) * Weight[3].x * Weight[2].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[3].x, Sample[3].y), 0).rgb, 1.0) * Weight[3].x * Weight[3].y;
    o_rgba += float4(Input.SampleLevel(sampler_Input_trilinear_clamp,float2(Sample[4].x, Sample[2].y), 0).rgb, 1.0) * Weight[4].x * Weight[2].y;


    float3 minCol = 9999.0f;
    float3 maxCol = -9999.0f;
int SampleCount = min(PrevOutput[newUV * float2(target_width, target_height)].w,300);

    [unroll]for(int x = -1; x <= 1; ++x) {
        [unroll]for(int y = -1; y <= 1; ++y) {
            int2 OffsetIndex = newUV * float2(target_width, target_height) + int2(x,y);
            if(any(OffsetIndex >= int2(target_width, target_height)) || any(OffsetIndex <= 0)) continue;
            float3 color = PrevOutput[OffsetIndex].xyz;
            minCol = min(minCol, color);
            maxCol = max(maxCol, color);
        }
    }
    float3 CurrentColor = o_rgba.xyz / o_rgba.w;
    if(!(luminance(CurrentColor) >= luminance(minCol) && luminance(CurrentColor) <= luminance(maxCol))) {Disocluded = true; SampleCount = 0;}
    if(abs(luminance(CurrentColor - Input.SampleLevel(sampler_Input_trilinear_clamp,UV2, 0).rgb)) > 0.25f) {Disocluded = true; SampleCount = 0;}

        PrevNormalTexWrite[id.xy] = NormalTex[id.xy];
        if(Disocluded) PrevWorldPosWrite[id.xy] = float4(WorldPos,1);
        else {
            PrevWorldPosWrite[id.xy] = PrevWorldPos[newUV * float2(target_width, target_height)];
        }

    #ifdef HDRP
        float3 SpecularAlbedo = 0;//Albedo2[int3(ipos,0)].xyz;
    #else
        float3 SpecularAlbedo = Albedo2[id.xy].xyz;
    #endif
    // if(SpecularAlbedo.x == SpecularAlbedo.y && SpecularAlbedo.y == SpecularAlbedo.z) SpecularAlbedo = 0;
if(Disocluded) SampleCount *= clamp(dot(PrevNormalTex[newUV * float2(target_width, target_height)].xyz * 2.0 - 1.0f, NormalTex[id.xy].xyz * 2.0 - 1.0f),0,1.0f) * 0.1f;
    // Output[id.xy] = float4(lerp((o_rgba.rgb / o_rgba.w), PrevOutput[newUV * float2(target_width, target_height)].xyz, 0.25f),1);// * (Albedo[id.xy].xyz),1);
        Output[id.xy] = float4(lerp(PrevOutput[newUV * float2(target_width, target_height)].xyz, (o_rgba.rgb / o_rgba.w), rcp(SampleCount + 1)),SampleCount + 1);
    FinalOutput[id.xy] = float4(Output[id.xy] * ((all((Albedo[id.xy].xyz + SpecularAlbedo) == 0) ? 1 : ((Albedo[id.xy].xyz + (max(SpecularAlbedo,0.04f) - 0.04f))))), 1);
//     return o_rgba.rgb / o_rgba.w;


//         float4 super = super_sample(UV, id.xyxy / float2(target_width, target_height).xyxy, view_pixel_size);
// // Disocluded = Disocluded || abs(dot(lerp(dir_avg.xyz, super.xyz, 0.5f), float3(0.299f, 0.587f, 0.114f)) - dot(PrevOutput[newUV * float2(target_width, target_height)].xyz, float3(0.299f, 0.587f, 0.114f))) > 0.1f;
//         float3 SpecularAlbedo = Albedo2[id.xy].xyz;
//         if(SpecularAlbedo.x == SpecularAlbedo.y && SpecularAlbedo.y == SpecularAlbedo.z) SpecularAlbedo = 0;
//         if(Disocluded || (newUV.x > 1 || newUV.x < 0 || newUV.y > 1 || newUV.y < 0) || true) Output[id.xy] = float4(lerp(dir_avg.xyz, super.xyz, 0.5f),1);
    // FinalOutput[id.xy] = float4((Output[id.xy].xyz * (Albedo[id.xy].xyz + Albedo2[id.xy].xyz) < 100000) ? ((all(Albedo[id.xy].xyz + SpecularAlbedo == 0) ? Output[id.xy].xyz : (Output[id.xy].xyz * (Albedo[id.xy].xyz + SpecularAlbedo)))) : 0, 1);
}