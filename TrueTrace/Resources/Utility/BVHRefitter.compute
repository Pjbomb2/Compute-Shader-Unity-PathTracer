#define KernelRatio 256

#pragma kernel Construct


struct TriangleData {
	float3 V1, V2, V3;
	float3 Norm1, Norm2, Norm3;
};

StructuredBuffer<TriangleData> VertexsIn;

StructuredBuffer<int> CWBVHIndices;
ByteAddressBuffer bufVertices;

ByteAddressBuffer bufIndexes;

uint gVertexCount;

int VertOffset;

float4x4 Transform;
float4x4 Transform2;
float4x4 Transform3;

float3 Offset;
float3 OverallOffset;
float3 ArmetureOffset;

float3 Scale;

float ArmetureScale;

struct AdvancedTriangle {
	float3 BBMax;//12
	float3 BBMin;//24
};

RWStructuredBuffer<AdvancedTriangle> AdvancedTriangles;

struct CudaTriangle {
	float3 pos0;
	float3 posedge1;
	float3 posedge2;

	uint3 norms;

	uint3 tans;

	float2 tex0;
	float2 texedge1;
	float2 texedge2;

	uint MatDat;
};

StructuredBuffer<CudaTriangle> CudaTriArrayIN;
RWStructuredBuffer<CudaTriangle> CudaTriArray;

float2 msign( float2 v )
{
    return float2( (v.x>=0.0) ? 1.0 : -1.0, 
                 (v.y>=0.0) ? 1.0 : -1.0 );
}

uint octahedral_32( in float3 nor )
{
    nor.xy /= ( abs( nor.x ) + abs( nor.y ) + abs( nor.z ) );
    nor.xy  = (nor.z >= 0.0) ? nor.xy : (1.0-abs(nor.yx))*msign(nor.xy);
    //return packSnorm2x16(nor.xy);
    uint2 d = uint2(round(32767.5 + nor.xy*32767.5));  return d.x|(d.y<<16u);
}
int TriBuffOffset;
[numthreads(KernelRatio, 1, 1)]
void Construct(uint3 id : SV_DispatchThreadID)
{
	if (id.x >= gVertexCount)
		return;

	uint3 vidx = uint3(bufIndexes.Load(id.x * 12), bufIndexes.Load(id.x * 12 + 8), bufIndexes.Load(id.x * 12 + 4)) * 10;

	uint3 praw = bufVertices.Load3((vidx.x) << 2);
	float3 p = asfloat(praw);

	praw = bufVertices.Load3((vidx.y) << 2);
	float3 p2 = asfloat(praw);

	praw = bufVertices.Load3((vidx.z) << 2);
	float3 p3 = asfloat(praw);

	praw = bufVertices.Load3((vidx.x + 3) << 2);
	float3 n1 = asfloat(praw);

	praw = bufVertices.Load3((vidx.y + 3) << 2);
	float3 n2 = asfloat(praw);

	praw = bufVertices.Load3((vidx.z + 3) << 2);
	float3 n3 = asfloat(praw);
	int VertOfst = VertOffset + id.x;

	AdvancedTriangle TempAdvTri = AdvancedTriangles[CWBVHIndices[VertOfst]];
	CudaTriangle TempTri = CudaTriArrayIN[CWBVHIndices[VertOfst]];
	
	float3 Offset3 = mul(Transform3, float4(Offset, 0)).xyz + mul(Transform3, float4(OverallOffset, 0)).xyz + mul(Transform3, float4(ArmetureOffset, 0)).xyz;
	p *= ArmetureScale;
	p2 *= ArmetureScale;
	p3 *= ArmetureScale;
	p /= Scale * Scale;
	p2 /= Scale * Scale;
	p3 /= Scale * Scale;
	p = mul(float4(p, 0), Transform).xyz;
	p2 = mul(float4(p2, 0), Transform).xyz;
	p3 = mul(float4(p3, 0), Transform).xyz;

	p = mul(float4(p, 0), Transform2).xyz;
	p2 = mul(float4(p2, 0), Transform2).xyz;
	p3 = mul(float4(p3, 0), Transform2).xyz;

	p += Offset3;
	p2 += Offset3;
	p3 += Offset3;

	float3 Norm1 = mul(float4(mul(float4(n1, 0), Transform).xyz, 0), Transform2).xyz;
	float3 Norm2 = mul(float4(mul(float4(n2, 0), Transform).xyz, 0), Transform2).xyz;
	float3 Norm3 = mul(float4(mul(float4(n3, 0), Transform).xyz, 0), Transform2).xyz;

	float3 BBMax = max(max(p, p2), p3);
	float3 BBMin = min(min(p, p2), p3);
	[unroll] for (int i2 = 0; i2 < 3; i2++) {
		if (BBMax[i2] - BBMin[i2] < 0.0000001f) {
			BBMin[i2] -= 0.0000001f;
			BBMax[i2] += 0.0000001f;
		}
	}
	TempAdvTri.BBMax = BBMax;
	TempAdvTri.BBMin = BBMin;

	AdvancedTriangles[CWBVHIndices[VertOfst]] = TempAdvTri;

	TempTri.pos0 = p;
	TempTri.posedge1 = p2 - p;
	TempTri.posedge2 = p3 - p;

	TempTri.norms.x = octahedral_32(Norm1);

	TempTri.norms.y = octahedral_32(Norm2);
	TempTri.norms.z = octahedral_32(Norm3);
	CudaTriArray[CWBVHIndices[VertOfst] + TriBuffOffset] = TempTri;
}





struct NodeIndexPairData {
	int PreviousNode;//4
	int BVHNode;//8
	int Node;//12
	float3 BBMax;//24
	float3 BBMin;//36
	int InNodeOffset;//40
	int isLeaf;
	int RecursionCount;
};

RWStructuredBuffer<NodeIndexPairData> AllNodes;

StructuredBuffer<int2> TriPair;


#pragma kernel RefitLayer



struct Layer {
	int Children[8];
	int Leaf[8];
};

StructuredBuffer<int> NodesToWork;
uint NodeCount;

StructuredBuffer<Layer> ReverseStack;


[numthreads(KernelRatio, 1, 1)]
void RefitLayer(uint3 id : SV_DispatchThreadID)
{
	if (id.x > NodeCount)
		return;
	const int CurrentParent = NodesToWork[id.x];

	float3 RunningMax = AllNodes[CurrentParent].BBMax;
	float3 RunningMin = AllNodes[CurrentParent].BBMin;
	const Layer CurrentLayer = ReverseStack[CurrentParent];
	[unroll]
	for (int i = 0; i < 8; i++) {
		[branch] if (CurrentLayer.Leaf[i] == 0) {
			RunningMax = max(RunningMax, AllNodes[CurrentLayer.Children[i]].BBMax);
			RunningMin = min(RunningMin, AllNodes[CurrentLayer.Children[i]].BBMin);
		}
		else if (CurrentLayer.Leaf[i] > 0) {
			int Max = CurrentLayer.Children[i];
			for (int i4 = CurrentLayer.Leaf[i] - 1; i4 < Max; i4++) {
				RunningMax = max(RunningMax, AdvancedTriangles[i4].BBMax);
				RunningMin = min(RunningMin, AdvancedTriangles[i4].BBMin);
			}

		}
	}

	AllNodes[CurrentParent].BBMax = RunningMax;
	AllNodes[CurrentParent].BBMin = RunningMin;

}

#pragma kernel RefitBVHLayer

struct BoundingBox {
	float3 BBMax;
	float3 BBMin;
};
StructuredBuffer<BoundingBox> Boxs;
[numthreads(KernelRatio, 1, 1)]
void RefitBVHLayer(uint3 id : SV_DispatchThreadID)
{
	if (id.x > NodeCount)
		return;
	const int CurrentParent = NodesToWork[id.x];

	float3 RunningMax = AllNodes[CurrentParent].BBMax;
	float3 RunningMin = AllNodes[CurrentParent].BBMin;
	const Layer CurrentLayer = ReverseStack[CurrentParent];
	[unroll]
	for (int i = 0; i < 8; i++) {
		[branch] if (CurrentLayer.Leaf[i] == 0) {
			RunningMax = max(RunningMax, AllNodes[CurrentLayer.Children[i]].BBMax);
			RunningMin = min(RunningMin, AllNodes[CurrentLayer.Children[i]].BBMin);
		}
		else if (CurrentLayer.Leaf[i] > 0) {
			for (int i4 = CurrentLayer.Leaf[i] - 1; i4 < CurrentLayer.Children[i] + CurrentLayer.Leaf[i] - 1; i4++) {
				RunningMax = max(RunningMax, Boxs[i4].BBMax);
				RunningMin = min(RunningMin, Boxs[i4].BBMin);
			}

		}
	}

	AllNodes[CurrentParent].BBMax = RunningMax;
	AllNodes[CurrentParent].BBMin = RunningMin;

}


#pragma kernel NodeUpdate

struct BVHNode8Data {
	float3 p;//12
	uint e[3];//24
	uint imask;//28    
	uint base_index_child;//32;
	uint base_index_triangle;//36;
	uint meta[8];
	uint quantized_min_x[8];
	uint quantized_max_x[8];
	uint quantized_min_y[8];
	uint quantized_max_y[8];
	uint quantized_min_z[8];
	uint quantized_max_z[8];//2
};

StructuredBuffer<int> ToBVHIndex;

RWStructuredBuffer<BVHNode8Data> BVHNodes;


[numthreads(KernelRatio, 1, 1)]
void NodeUpdate(uint3 id : SV_DispatchThreadID)
{
	if (id.x >= NodeCount || id.x == 0)
		return;
	NodeIndexPairData TempNode = AllNodes[id.x];
	int NodeLink = ToBVHIndex[TempNode.BVHNode];
	BVHNode8Data TempBVHNode = BVHNodes[TempNode.BVHNode];
	float3 BBMax = AllNodes[NodeLink].BBMax;
	float3 BBMin = AllNodes[NodeLink].BBMin;
	[branch] if (TempNode.BBMax.x < -10000.0f) {
		TempNode.BBMax = BBMin;
		TempNode.BBMin = BBMin;
	}
	const uint BVHNodeOffset = TempNode.BVHNode;
	float3 e = pow(2, ceil(log2((BBMax - BBMin) * 0.003921569f)));
	float3 p = BBMin;
	const uint3 Max = ceil((TempNode.BBMax - p) / e);
	const uint3 Min = floor((TempNode.BBMin - p) / e);
	BVHNodes[BVHNodeOffset].p = p;
	uint u_ex = asuint(e.x);
	uint u_ey = asuint(e.y);
	uint u_ez = asuint(e.z);
	const uint NodeOffset = TempNode.InNodeOffset;
	BVHNodes[BVHNodeOffset].e[0] = u_ex >> 23;
	BVHNodes[BVHNodeOffset].e[1] = u_ey >> 23;
	BVHNodes[BVHNodeOffset].e[2] = u_ez >> 23;
	BVHNodes[BVHNodeOffset].quantized_max_x[NodeOffset] = Max.x;
	BVHNodes[BVHNodeOffset].quantized_max_y[NodeOffset] = Max.y;
	BVHNodes[BVHNodeOffset].quantized_max_z[NodeOffset] = Max.z;
	BVHNodes[BVHNodeOffset].quantized_min_x[NodeOffset] = Min.x;
	BVHNodes[BVHNodeOffset].quantized_min_y[NodeOffset] = Min.y;
	BVHNodes[BVHNodeOffset].quantized_min_z[NodeOffset] = Min.z;



}





#pragma kernel NodeCompress



struct BVHNode8DataCompressed {
	float3 node_0xyz;
	uint node_0w;
	uint node_1x;
	uint node_1y;
	uint node_1z;
	uint node_1w;
	uint node_2x;
	uint node_2y;
	uint node_2z;
	uint node_2w;
	uint node_3x;
	uint node_3y;
	uint node_3z;
	uint node_3w;
	uint node_4x;
	uint node_4y;
	uint node_4z;
	uint node_4w;
};

RWStructuredBuffer<BVHNode8DataCompressed> AggNodes;


int NodeOffset;
[numthreads(KernelRatio, 1, 1)]
void NodeCompress(uint3 id : SV_DispatchThreadID)
{
	if (id.x >= NodeCount)
		return;
	const BVHNode8Data TempNode = BVHNodes[id.x];
	BVHNode8DataCompressed TempBVHNode = AggNodes[id.x + NodeOffset];

	TempBVHNode.node_0xyz = float3(TempNode.p.x, TempNode.p.y, TempNode.p.z);
	TempBVHNode.node_0w = (TempNode.e[0] | (TempNode.e[1] << 8) | (TempNode.e[2] << 16) | (TempNode.imask << 24));
	TempBVHNode.node_1x = TempNode.base_index_child;
	TempBVHNode.node_1y = TempNode.base_index_triangle;
	TempBVHNode.node_1z = (TempNode.meta[0] | (TempNode.meta[1] << 8) | (TempNode.meta[2] << 16) | (TempNode.meta[3] << 24));
	TempBVHNode.node_1w = (TempNode.meta[4] | (TempNode.meta[5] << 8) | (TempNode.meta[6] << 16) | (TempNode.meta[7] << 24));
	TempBVHNode.node_2x = (TempNode.quantized_min_x[0] | (TempNode.quantized_min_x[1] << 8) | (TempNode.quantized_min_x[2] << 16) | (TempNode.quantized_min_x[3] << 24));
	TempBVHNode.node_2y = (TempNode.quantized_min_x[4] | (TempNode.quantized_min_x[5] << 8) | (TempNode.quantized_min_x[6] << 16) | (TempNode.quantized_min_x[7] << 24));
	TempBVHNode.node_2z = (TempNode.quantized_max_x[0] | (TempNode.quantized_max_x[1] << 8) | (TempNode.quantized_max_x[2] << 16) | (TempNode.quantized_max_x[3] << 24));
	TempBVHNode.node_2w = (TempNode.quantized_max_x[4] | (TempNode.quantized_max_x[5] << 8) | (TempNode.quantized_max_x[6] << 16) | (TempNode.quantized_max_x[7] << 24));
	TempBVHNode.node_3x = (TempNode.quantized_min_y[0] | (TempNode.quantized_min_y[1] << 8) | (TempNode.quantized_min_y[2] << 16) | (TempNode.quantized_min_y[3] << 24));
	TempBVHNode.node_3y = (TempNode.quantized_min_y[4] | (TempNode.quantized_min_y[5] << 8) | (TempNode.quantized_min_y[6] << 16) | (TempNode.quantized_min_y[7] << 24));
	TempBVHNode.node_3z = (TempNode.quantized_max_y[0] | (TempNode.quantized_max_y[1] << 8) | (TempNode.quantized_max_y[2] << 16) | (TempNode.quantized_max_y[3] << 24));
	TempBVHNode.node_3w = (TempNode.quantized_max_y[4] | (TempNode.quantized_max_y[5] << 8) | (TempNode.quantized_max_y[6] << 16) | (TempNode.quantized_max_y[7] << 24));
	TempBVHNode.node_4x = (TempNode.quantized_min_z[0] | (TempNode.quantized_min_z[1] << 8) | (TempNode.quantized_min_z[2] << 16) | (TempNode.quantized_min_z[3] << 24));
	TempBVHNode.node_4y = (TempNode.quantized_min_z[4] | (TempNode.quantized_min_z[5] << 8) | (TempNode.quantized_min_z[6] << 16) | (TempNode.quantized_min_z[7] << 24));
	TempBVHNode.node_4z = (TempNode.quantized_max_z[0] | (TempNode.quantized_max_z[1] << 8) | (TempNode.quantized_max_z[2] << 16) | (TempNode.quantized_max_z[3] << 24));
	TempBVHNode.node_4w = (TempNode.quantized_max_z[4] | (TempNode.quantized_max_z[5] << 8) | (TempNode.quantized_max_z[6] << 16) | (TempNode.quantized_max_z[7] << 24));
	AggNodes[id.x + NodeOffset] = TempBVHNode;
}





#pragma kernel NodeInitializer



[numthreads(KernelRatio, 1, 1)]
void NodeInitializer(uint3 id : SV_DispatchThreadID)
{
	if (id.x > NodeCount)
		return;

	AllNodes[id.x].BBMax = -9999999999.0f;
	AllNodes[id.x].BBMin = 9999999999.0f;


}